---
title: "p8105_hw5_jh4324"
author: "Jiying Han"
date: "11/13/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(stats)
library(purrr)

knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d



```

This is my solution for HW5

## Problem 1

read in the data
```{r}
homicide_df = 
  read.csv("./data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest"~"unsolved",
      disposition == "Open/No arrest"~"unsolved",
      disposition == "Closed by arrest"~"solved"
    )
   ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") 

```

let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

can i do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
 broom::tidy() 
```

try to iterate...

```{r}
result_df = 
  aggregate_df %>% 
   mutate(
     prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n =.y)),
     tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
   ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

make a plot

```{r}
result_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5, hjust = 1))
```


## Problem 2


import one dataset
```{r error = TRUE}
path_df =
  tibble(
  path = list.files("./data/data2")
) %>% 
  mutate(path = str_c("./data/data2/", path),
         observations = map(.x = path, ~read_csv(.x))
         ) %>% 
  separate(path,c("subject_id","format"),sep = ".csv" ) %>% 
  separate(subject_id,c("format","subject_id"),sep = "2/" ) %>% 
  select(-format) %>% 
  separate(subject_id,c("arm","subject_id"),sep = "_") %>% 
  mutate(
  arm = case_when(
      arm == "con"~"control",
      arm == "exp"~"experiment"
    )) %>% 
  unnest(observations) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to ="observations"
  ) %>% 
  mutate(
    week = str_replace(week,"week_",""),
    week = as.factor(week)) 

path_df %>% knitr::kable()
```


make a spaghetti plot
```{r error = TRUE}
spaghetti_plot = 
  path_df %>%
  unite("subjects", c(arm, subject_id), sep = "_", remove = TRUE, na.rm = FALSE) %>% 
  ggplot(aes(x = week, y = observations, group = subjects, color = subjects)) + 
  geom_path()

ggsave("spaghetti_plot.jpg")

spaghetti_plot
```

Comment: In these eight weeks, we can finds that in experimental groups, the overall  observational values are higher than the control groups. And the trend of the experimental groups is increasing. As for the control groups, the trend is approximately fluctuate without apparent increasing or decreasing.

## Problem 3 (simulation - ttest -  estimate - pvalue - plot/summarize of pvalue and estiamte by significant different or not)

Generate dataset

```{r}
set.seed(1000)
df = rerun(5000, map(.x = 0, ~rnorm(n = 30, mean = (.x), sd = 5)))

nd_ttest = function(mu){
  norm_df = 
    tibble(x = rnorm(mean = mu, n =30, sd = 5)) 
  
  norm_df %>% summarize(
    t.test(x, mean = 0,conf.level = 0.95) %>% 
    broom::tidy() %>%
    select(estimate,p.value)
                       )
   
}

set.seed(1000)
sample_df = function(mu){
  rerun(5000,map(.x = mu, ~nd_ttest(.x))) %>% 
  bind_rows()
}

sample_df(0)
```


Repeat the above

```{r}
set.seed(1000)
mu_df = 
  tibble(
    mu = c(0,1,2,3,4,5,6)
      ) %>% 
  mutate(
    output_lists = map(.x = mu, ~sample_df(.x))
  )

```


Summarize 

```{r}
set.seed(1000)
mureject_df = 
  mu_df %>% 
  unnest(output_lists) %>% 
  mutate(mu = as.numeric(mu)) %>% 
  group_by(mu) %>% 
  mutate(
    reject = case_when(
      p.value >= "0.05" ~1,
      p.value <= "0.05"~ 0
    )
  )  %>% 
  mutate(
    mu = as.factor(mu),
    reject = as.numeric(reject)) %>% 
  select(mu,reject) %>% 
  group_by(mu) %>% 
  summarize(
    test_total = n(),
    reject_total = sum(reject == "1" ),
    proportion = reject_total/test_total
  )
    

```


plot - proportion of time the null was rejected

```{r}
set.seed(1000)
mureject_df %>% 
  mutate(mu = as.numeric(mu)) %>% 
  ggplot(aes( x = mu , y = proportion), color = mu) + 
  geom_point() +
  geom_line() +
  labs(
    title = "Association between effect size and power",
    x = "True μ",
    y = "Proportion of times the null was rejected"
  )
  
```

Describe the association between effect size and power.



plot - Average estimate of μ hat and true value of μ
```{r}
 mu_df %>% 
  unnest(output_lists) %>% 
  mutate(mu = as.numeric(mu)) %>% 
  group_by(mu) %>% 
  summarize(
    average_estimate = mean(estimate)
  ) %>% 
  ggplot(aes(x = mu, y = average_estimate)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Average estimate of μ hat and true value of μ",
    x = "True value of μ",
    y = "Average estimate of μ hat "
   )
```


plot - Average estimate of μ hat only in samples for which the null was rejected and true value of μ 
```{r}
mu_df %>% 
  unnest(output_lists) %>% 
  mutate(
    mu = as.numeric(mu),
    reject = case_when(
      p.value >= "0.05" ~1,
      p.value <= "0.05"~ 0
    )
  ) %>% 
  filter(reject == "0") %>% 
  group_by(mu) %>% 
  summarize(
    average_estimate = mean(estimate)
   ) %>% 
  ggplot(aes( x = mu, y = average_estimate)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Average estimate of μ hat only in samples for which the null was rejected and true value of μ ",
    x = "True value of μ",
    y = "Average estimate of μ hat"
  )
```


Is the sample average of μ̂
 across tests for which the null is rejected approximately equal to the true value of μ
? Why or why not?


